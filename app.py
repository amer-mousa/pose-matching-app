
import streamlit as st
import cv2
import mediapipe as mp
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import tempfile
import os

st.set_page_config(page_title="ØªØ­Ù„ÙŠÙ„ Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ù…Ù‡Ø§Ø±Ø§Øª", layout="centered")
st.title("ğŸ¯ ØªÙ‚ÙŠÙŠÙ… Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ù…Ù‡Ø§Ø±Ø© Ù…Ù† Ø§Ù„ÙÙŠØ¯ÙŠÙˆ")

mp_pose = mp.solutions.pose

def extract_landmarks_from_video(video_path):
    pose = mp_pose.Pose(static_image_mode=False)
    cap = cv2.VideoCapture(video_path)
    landmarks_list = []

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        result = pose.process(frame_rgb)
        if result.pose_landmarks:
            landmarks = [(lm.x, lm.y, lm.z) for lm in result.pose_landmarks.landmark]
            landmarks_list.append(landmarks)
    cap.release()
    return landmarks_list

def calculate_similarity(ref_landmarks, live_landmarks):
    min_len = min(len(ref_landmarks), len(live_landmarks))
    similarities = []
    for i in range(min_len):
        ref_vec = np.array(ref_landmarks[i]).flatten().reshape(1, -1)
        live_vec = np.array(live_landmarks[i]).flatten().reshape(1, -1)
        sim = cosine_similarity(ref_vec, live_vec)[0][0]
        similarities.append(sim)
    return np.mean(similarities)

reference_video = st.file_uploader("ğŸ“¥ Ø­Ù…Ù‘Ù„ ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ù…Ù‡Ø§Ø±Ø© Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ", type=["mp4", "mov"])

if reference_video:
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as ref_tmp:
        ref_tmp.write(reference_video.read())
        ref_path = ref_tmp.name

    st.video(ref_path)
    st.info("ğŸ“ˆ ÙŠØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Ù‚Ø§Ø· Ø§Ù„Ù…ÙØ§ØµÙ„ Ù…Ù† Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ...")
    ref_landmarks = extract_landmarks_from_video(ref_path)
    st.success(f"âœ… ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ {len(ref_landmarks)} Ø¥Ø·Ø§Ø±Ù‹Ø§ Ø¨Ù†Ø¬Ø§Ø­.")

    st.header("ğŸ¥ ØªØµÙˆÙŠØ± Ù…Ø¨Ø§Ø´Ø± Ø¨Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§")
    run_camera = st.button("ğŸ”´ Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ù…Ù† Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§")

    if run_camera:
        st.warning("ğŸ“¸ ÙŠØªÙ… ÙØªØ­ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ Ø§Ù„Ø¢Ù†. Ø§Ø¶ØºØ· Ø¹Ù„Ù‰ 'Q' Ù…Ù† Ø§Ù„Ù†Ø§ÙØ°Ø© Ù„Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªØ³Ø¬ÙŠÙ„.")
        live_path = os.path.join(tempfile.gettempdir(), "live_capture.mp4")
        cap = cv2.VideoCapture(0)
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(live_path, fourcc, 10.0, (640, 480))

        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            out.write(frame)
            cv2.imshow('Ø§Ø¶ØºØ· Q Ù„Ø¥Ù†Ù‡Ø§Ø¡ Ø§Ù„ØªØ³Ø¬ÙŠÙ„', frame)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

        cap.release()
        out.release()
        cv2.destroyAllWindows()

        st.success("âœ… ØªÙ… Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ù…Ù† Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§.")
        st.video(live_path)
        st.info("âš™ï¸ ÙŠØªÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ ÙˆÙ…Ù‚Ø§Ø±Ù†ØªÙ‡...")

        live_landmarks = extract_landmarks_from_video(live_path)
        score = calculate_similarity(ref_landmarks, live_landmarks)
        st.success(f"ğŸ¯ Ø¯Ø±Ø¬Ø© Ø§Ù„ØªØ·Ø§Ø¨Ù‚: {score * 10:.2f} Ù…Ù† 10")
