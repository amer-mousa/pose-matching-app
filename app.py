import streamlit as st
import cv2
import mediapipe as mp
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import tempfile

mp_pose = mp.solutions.pose

def extract_landmarks(video_path):
    cap = cv2.VideoCapture(video_path)
    pose = mp_pose.Pose()
    lms = []
    while True:
        success, frame = cap.read()
        if not success:
            break
        res = pose.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        if res.pose_landmarks:
            lms.append([(lm.x, lm.y, lm.z) for lm in res.pose_landmarks.landmark])
    cap.release()
    return lms

st.title("ğŸ§  ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ù‡Ø§Ø±Ø§Øª Ø§Ù„Ø­Ø±ÙƒÙŠØ©")

ref_video = st.file_uploader("ğŸ“¥ Ø­Ù…Ù‘Ù„ ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ù…Ù‡Ø§Ø±Ø© Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ", type=["mp4"])
live_video = st.file_uploader("ğŸ“· Ø­Ù…Ù‘Ù„ ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø©", type=["mp4"])

if ref_video:
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tmp:
        tmp.write(ref_video.read())
        ref_path = tmp.name
    ref_lm = extract_landmarks(ref_path)
    st.success(f"âœ… Ø§Ø³ØªØ®Ø±Ø¬Ù†Ø§ {len(ref_lm)} Ø¥Ø·Ø§Ø± Ù…Ù† Ø§Ù„Ù…Ø±Ø¬Ø¹.")

if ref_video and live_video:
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tmp2:
        tmp2.write(live_video.read())
        live_path = tmp2.name
    live_lm = extract_landmarks(live_path)
    st.success(f"âœ… Ø§Ø³ØªØ®Ø±Ø¬Ù†Ø§ {len(live_lm)} Ø¥Ø·Ø§Ø± Ù…Ù† Ø§Ù„Ø£Ø¯Ø§Ø¡.")

    # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡
    n = min(len(ref_lm), len(live_lm))
    if n == 0:
        st.error("âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¥Ø·Ø§Ø±Ø§Øª ÙƒØ§ÙÙŠØ© Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø©.")
    else:
        sims = []
        for i in range(n):
            a = np.array(ref_lm[i]).flatten().reshape(1, -1)
            b = np.array(live_lm[i]).flatten().reshape(1, -1)
            sims.append(cosine_similarity(a, b)[0][0])
        score = np.mean(sims)*10
        st.success(f"ğŸ¯ Ø¯Ø±Ø¬Ø© Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©: {score:.2f} Ù…Ù† 10")
